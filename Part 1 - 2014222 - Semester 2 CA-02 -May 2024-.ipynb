{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894d7f93",
   "metadata": {},
   "source": [
    "# 2014222 - Semester 2 CA-02 -May 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe76a6",
   "metadata": {},
   "source": [
    "### Github account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3c9a4",
   "metadata": {},
   "source": [
    "https://github.com/2014222-student-cct-ie/2024--Semester-2--CA2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9df824",
   "metadata": {},
   "source": [
    "### Analysis of a large dataset gleaned from the twitter API and is available on Moodle as “ProjectTweets.csv”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6de15a",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7969d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilise Python programming language in order to comply with the requisites of the assessment and perform adequate Machine\n",
    "# Learning algorithms to discover and deliver insights.\n",
    "\n",
    "# Import the necessary libraries (Numpy and Pandas) in order to perform data cleansing.\n",
    "# These are the libraries that are conventionally used as a common practice in order to\n",
    "# perform mathematical and statistical operations during a data analysis process\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Matplotlib and Plotly library in order to perform data visualisation procedures\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I am using this line of code to see all columns in a wide DataFrame\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "\n",
    "# For normalization\n",
    "from pyspark.ml.feature import MinMaxScaler \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "\n",
    "# process the tweets data\n",
    "# !pip install textblob\n",
    "from pyspark.sql.functions import udf\n",
    "from textblob import TextBlob\n",
    "\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# re module provides regular expression support.\n",
    "# In Python a regular expression search is typically written as:\n",
    "# match = re. search(pat, str)\n",
    "# The re.search() method takes a regular expression pattern and a string and searches\n",
    "# for that pattern within the string.\n",
    "\n",
    "import re\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "#!pip install pyspark\n",
    "\n",
    "# Import the warnings module\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings by applying th the 'filterwarnings()'' function and passing the 'ignore' argument\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c020c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file by applying the pd.read_csv() function.\n",
    "\n",
    "tweets_dataset = pd.read_csv('ProjectTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0085e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>1599995</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1599996</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1599997</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1599998</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1599999</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "0              1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1              2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2              3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3              4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4              5  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "1599994  1599995  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995  1599996  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  1599997  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  1599998  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  1599999  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "         _TheSpecialOne_  \\\n",
       "0          scotthamilton   \n",
       "1               mattycus   \n",
       "2                ElleCTF   \n",
       "3                 Karoli   \n",
       "4               joy_wolf   \n",
       "...                  ...   \n",
       "1599994  AmandaMarie1028   \n",
       "1599995      TheWDBoards   \n",
       "1599996           bpbabe   \n",
       "1599997     tinydiamondz   \n",
       "1599998   RyanTrevMorris   \n",
       "\n",
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0        is upset that he can't update his Facebook by ...                                                                   \n",
       "1        @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2          my whole body feels itchy and like its on fire                                                                    \n",
       "3        @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                            @Kwesidei not the whole crew                                                                    \n",
       "...                                                    ...                                                                   \n",
       "1599994  Just woke up. Having no school is the best fee...                                                                   \n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...                                                                   \n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...                                                                   \n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...                                                                   \n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...                                                                   \n",
       "\n",
       "[1599999 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the tweets_dataset\n",
    "\n",
    "tweets_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591ade3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimensions of the tweets_dataset DataFrame.\n",
    "\n",
    "tweets_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597262e6",
   "metadata": {},
   "source": [
    "As we can see that the tweets dataframe contains 1599999 rows × 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f631ce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  5  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 rows of the tweets dataframe by applying the .head() method,\n",
    "# This method is will display the top 5 observations of the dataset\n",
    "\n",
    "tweets_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9734b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                      1599999\n",
       "1467810369                                                                                                             1598314\n",
       "Mon Apr 06 22:19:45 PDT 2009                                                                                            774362\n",
       "NO_QUERY                                                                                                                     1\n",
       "_TheSpecialOne_                                                                                                         659775\n",
       "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D    1581465\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting several unique values in each columnan the data description the tweets dataframe\n",
    "# by applying the .nunique() method,\n",
    "# Will display continuous and categorical columns in the data.\n",
    "# Duplicated data can be handled or removed based on further analysis\n",
    "# helps to understand the data type and information about data\n",
    "\n",
    "tweets_dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf725348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>1599995</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1599996</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1599997</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1599998</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1599999</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "1599994  1599995  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995  1599996  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  1599997  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  1599998  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  1599999  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "         _TheSpecialOne_  \\\n",
       "1599994  AmandaMarie1028   \n",
       "1599995      TheWDBoards   \n",
       "1599996           bpbabe   \n",
       "1599997     tinydiamondz   \n",
       "1599998   RyanTrevMorris   \n",
       "\n",
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1599994  Just woke up. Having no school is the best fee...                                                                   \n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...                                                                   \n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...                                                                   \n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...                                                                   \n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...                                                                   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the last 5 rows of the tweets dataframe by applying the .tail() method,\n",
    "# Will display the last 5 observations of the dataset\n",
    "\n",
    "tweets_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edb901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                                                                                               Non-Null Count    Dtype \n",
      "---  ------                                                                                                               --------------    ----- \n",
      " 0   0                                                                                                                    1599999 non-null  int64 \n",
      " 1   1467810369                                                                                                           1599999 non-null  int64 \n",
      " 2   Mon Apr 06 22:19:45 PDT 2009                                                                                         1599999 non-null  object\n",
      " 3   NO_QUERY                                                                                                             1599999 non-null  object\n",
      " 4   _TheSpecialOne_                                                                                                      1599999 non-null  object\n",
      " 5   @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Getting information about the tweets dataframe by applying the .info() method,\n",
    "# Will display number of records in each column, data having null or not null, Data type,\n",
    "# memory usage of the dataset\n",
    "# helps to understand the data type and information about data\n",
    "\n",
    "tweets_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d6f4b",
   "metadata": {},
   "source": [
    "As we can see the tweets dataset is structured into a table with almost 1.6 million tweets, spread across six columns, each storing different pieces of information about the tweets such as ID, timestamp, query flag, user, and tweet text.\n",
    "\n",
    "The data types vary from integers for numeric data to objects for textual data.\n",
    "\n",
    "The tweets dataset doesn't have proper headers, which is why pandas is using the first row as column names by default.\n",
    "\n",
    "Therefore we need to clean this by assigning proper column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15dd2468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>date_timestamp</th>\n",
       "      <th>query</th>\n",
       "      <th>twitter_user</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    tweet_ID                date_timestamp     query     twitter_user  \\\n",
       "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1      1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2      2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3      3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4      4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning proper column names.\n",
    "\n",
    "columns = ['index', 'tweet_ID', 'date_timestamp', 'query', 'twitter_user', 'tweet_text']\n",
    "\n",
    "tweets_dataset = pd.read_csv('ProjectTweets.csv',header=None,names=columns,delimiter=',')\n",
    "\n",
    "tweets_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aaad64",
   "metadata": {},
   "source": [
    "**As we can see the column index has a duplicate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385bcf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column called 'Index'\n",
    "\n",
    "tweets_dataset = tweets_dataset.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6772791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>date_timestamp</th>\n",
       "      <th>query</th>\n",
       "      <th>twitter_user</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_ID                date_timestamp     query     twitter_user  \\\n",
       "0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the tweets_dataset to confirm the column has been dropped\n",
    "\n",
    "tweets_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a814fb",
   "metadata": {},
   "source": [
    "The column called query only has 1 value which says NO_QUERY\n",
    "\n",
    "Therefore I am going to drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9704b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column called query only has 1 value which says NO_QUERY,\n",
      "Therefore we are going to drop this column\n",
      "\n",
      "Index(['tweet_ID', 'date_timestamp', 'twitter_user', 'tweet_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop the column called 'Query'\n",
    "\n",
    "if len(tweets_dataset['query'].unique()) <2:\n",
    "    \n",
    "    print(\"The column called query only has 1 value which says NO_QUERY,\"\n",
    "          \"\\nTherefore we are going to drop this column\\n\")\n",
    "    \n",
    "    tweets_dataset = tweets_dataset[[ 'tweet_ID', 'date_timestamp', 'twitter_user','tweet_text']]\n",
    "    \n",
    "    print(tweets_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3abe6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "\n",
    "tweets_dataset = tweets_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f326a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>date_timestamp</th>\n",
       "      <th>twitter_user</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_ID                date_timestamp     twitter_user  \\\n",
       "0  1467810369  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_   \n",
       "1  1467810672  Mon Apr 06 22:19:49 PDT 2009    scotthamilton   \n",
       "2  1467810917  Mon Apr 06 22:19:53 PDT 2009         mattycus   \n",
       "3  1467811184  Mon Apr 06 22:19:57 PDT 2009          ElleCTF   \n",
       "4  1467811193  Mon Apr 06 22:19:57 PDT 2009           Karoli   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 rows of the tweets dataframe by applying the .head() method,\n",
    "# This method is will display the top 5 observations of the dataset\n",
    "\n",
    "tweets_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f65d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1598315 entries, 0 to 1599999\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   tweet_ID        1598315 non-null  int64 \n",
      " 1   date_timestamp  1598315 non-null  object\n",
      " 2   twitter_user    1598315 non-null  object\n",
      " 3   tweet_text      1598315 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the information again to see how many entries remain\n",
    "\n",
    "tweets_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c43db0",
   "metadata": {},
   "source": [
    "**This information is helpful for diagnosing issues with data processing and understanding the structure of the Tweets dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5d8f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_ID          0\n",
       "date_timestamp    0\n",
       "twitter_user      0\n",
       "tweet_text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying missing values in the Tweets dataframe by applying the .isna().sum() methods,\n",
    "# I am using this to get the number of missing records in each column\n",
    "\n",
    "tweets_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8c59f",
   "metadata": {},
   "source": [
    "## Cleaning the text on the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadb696",
   "metadata": {},
   "source": [
    "The dataset has so many, @ mentions, hashtags, retweets, hyperlinks, and colons, emojis, unicode characters from a string, emoticons, dingbats, symbols & pictographs, transport & map symbols, flags (iOS), Chinese characters, etc.\n",
    "\n",
    "The idea is to clean te text on all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67362ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1     is upset that he can't update his Facebook by ...\n",
      "2     @Kenichan I dived many times for the ball. Man...\n",
      "3       my whole body feels itchy and like its on fire \n",
      "4     @nationwideclass no, it's not behaving at all....\n",
      "5                         @Kwesidei not the whole crew \n",
      "6                                           Need a hug \n",
      "7     @LOLTrish hey  long time no see! Yes.. Rains a...\n",
      "8                  @Tatiana_K nope they didn't have it \n",
      "9                             @twittera que me muera ? \n",
      "10          spring break in plain city... it's snowing \n",
      "11                           I just re-pierced my ears \n",
      "12    @caregiving I couldn't bear to watch it.  And ...\n",
      "13    @octolinz16 It it counts, idk why I did either...\n",
      "14    @smarrison i would've been the first, but i di...\n",
      "15    @iamjazzyfizzle I wish I got to watch it with ...\n",
      "16    Hollis' death scene will hurt me severely to w...\n",
      "17                                 about to file taxes \n",
      "18    @LettyA ahh ive always wanted to see rent  lov...\n",
      "19    @FakerPattyPattz Oh dear. Were you drinking ou...\n",
      "20    @alydesigns i was out most of the day so didn'...\n",
      "21    one of my friend called me, and asked to meet ...\n",
      "22     @angry_barista I baked you a cake but I ated it \n",
      "23               this week is not going as i had hoped \n",
      "24                           blagh class at 8 tomorrow \n",
      "25       I hate when I have to call and wake people up \n",
      "26    Just going to cry myself to sleep after watchi...\n",
      "27                               im sad now  Miss.Lilly\n",
      "28    ooooh.... LOL  that leslie.... and ok I won't ...\n",
      "29    Meh... Almost Lover is the exception... this t...\n",
      "Name: tweet_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Printing only the 'tweet_text' column\n",
    "\n",
    "print(tweets_dataset['tweet_text'].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56cbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2329d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the entire column\n",
    "\n",
    "tweets_dataset['cleaned_tweet_text'] = tweets_dataset['tweet_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "391294b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           tweet_text  \\\n",
      "0   @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1   is upset that he can't update his Facebook by ...   \n",
      "2   @Kenichan I dived many times for the ball. Man...   \n",
      "3     my whole body feels itchy and like its on fire    \n",
      "4   @nationwideclass no, it's not behaving at all....   \n",
      "5                       @Kwesidei not the whole crew    \n",
      "6                                         Need a hug    \n",
      "7   @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
      "8                @Tatiana_K nope they didn't have it    \n",
      "9                           @twittera que me muera ?    \n",
      "10        spring break in plain city... it's snowing    \n",
      "11                         I just re-pierced my ears    \n",
      "12  @caregiving I couldn't bear to watch it.  And ...   \n",
      "13  @octolinz16 It it counts, idk why I did either...   \n",
      "14  @smarrison i would've been the first, but i di...   \n",
      "15  @iamjazzyfizzle I wish I got to watch it with ...   \n",
      "16  Hollis' death scene will hurt me severely to w...   \n",
      "17                               about to file taxes    \n",
      "18  @LettyA ahh ive always wanted to see rent  lov...   \n",
      "19  @FakerPattyPattz Oh dear. Were you drinking ou...   \n",
      "20  @alydesigns i was out most of the day so didn'...   \n",
      "21  one of my friend called me, and asked to meet ...   \n",
      "22   @angry_barista I baked you a cake but I ated it    \n",
      "23             this week is not going as i had hoped    \n",
      "24                         blagh class at 8 tomorrow    \n",
      "25     I hate when I have to call and wake people up    \n",
      "26  Just going to cry myself to sleep after watchi...   \n",
      "27                             im sad now  Miss.Lilly   \n",
      "28  ooooh.... LOL  that leslie.... and ok I won't ...   \n",
      "29  Meh... Almost Lover is the exception... this t...   \n",
      "\n",
      "                                   cleaned_tweet_text  \n",
      "0   switchfoot httptwitpiccom2y1zl  Awww thats a b...  \n",
      "1   is upset that he cant update his Facebook by t...  \n",
      "2   Kenichan I dived many times for the ball Manag...  \n",
      "3     my whole body feels itchy and like its on fire   \n",
      "4   nationwideclass no its not behaving at all im ...  \n",
      "5                        Kwesidei not the whole crew   \n",
      "6                                         Need a hug   \n",
      "7   LOLTrish hey  long time no see Yes Rains a bit...  \n",
      "8                  Tatiana_K nope they didnt have it   \n",
      "9                             twittera que me muera    \n",
      "10            spring break in plain city its snowing   \n",
      "11                          I just repierced my ears   \n",
      "12  caregiving I couldnt bear to watch it  And I t...  \n",
      "13  octolinz16 It it counts idk why I did either y...  \n",
      "14  smarrison i wouldve been the first but i didnt...  \n",
      "15  iamjazzyfizzle I wish I got to watch it with y...  \n",
      "16  Hollis death scene will hurt me severely to wa...  \n",
      "17                               about to file taxes   \n",
      "18  LettyA ahh ive always wanted to see rent  love...  \n",
      "19  FakerPattyPattz Oh dear Were you drinking out ...  \n",
      "20  alydesigns i was out most of the day so didnt ...  \n",
      "21  one of my friend called me and asked to meet w...  \n",
      "22    angry_barista I baked you a cake but I ated it   \n",
      "23             this week is not going as i had hoped   \n",
      "24                         blagh class at 8 tomorrow   \n",
      "25     I hate when I have to call and wake people up   \n",
      "26  Just going to cry myself to sleep after watchi...  \n",
      "27                              im sad now  MissLilly  \n",
      "28  ooooh LOL  that leslie and ok I wont do it aga...  \n",
      "29  Meh Almost Lover is the exception this track g...  \n"
     ]
    }
   ],
   "source": [
    "# Print the first 20 rows of both the original and cleaned text columns\n",
    "\n",
    "print(tweets_dataset[['tweet_text', 'cleaned_tweet_text']].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44e9c095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Exporting the DataFrame to a CSV file\n",
    "\n",
    "tweets_dataset.to_csv('cleaned_tweet_text_file.csv', index=False)\n",
    "\n",
    "print('The CSV file has been created successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2349e2",
   "metadata": {},
   "source": [
    "# Initialize a SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7b32846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/07 19:14:39 WARN Utils: Your hostname, Geomars-Mac-Studio.local resolves to a loopback address: 127.0.0.1; using 192.168.0.110 instead (on interface en0)\n",
      "24/05/07 19:14:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/07 19:14:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CA2 Tweets Data Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d626f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------+--------------------+--------------------+\n",
      "|  tweet_ID|      date_timestamp|   twitter_user|          tweet_text|  cleaned_tweet_text|\n",
      "+----------+--------------------+---------------+--------------------+--------------------+\n",
      "|      NULL|      date_timestamp|   twitter_user|          tweet_text|  cleaned_tweet_text|\n",
      "|1467810369|Mon Apr 06 22:19:...|_TheSpecialOne_|@switchfoot http:...|switchfoot httptw...|\n",
      "|1467810672|Mon Apr 06 22:19:...|  scotthamilton|is upset that he ...|is upset that he ...|\n",
      "|1467810917|Mon Apr 06 22:19:...|       mattycus|@Kenichan I dived...|Kenichan I dived ...|\n",
      "|1467811184|Mon Apr 06 22:19:...|        ElleCTF|my whole body fee...|my whole body fee...|\n",
      "|1467811193|Mon Apr 06 22:19:...|         Karoli|@nationwideclass ...|nationwideclass n...|\n",
      "|1467811372|Mon Apr 06 22:20:...|       joy_wolf|@Kwesidei not the...|Kwesidei not the ...|\n",
      "|1467811592|Mon Apr 06 22:20:...|        mybirch|         Need a hug |         Need a hug |\n",
      "|1467811594|Mon Apr 06 22:20:...|           coZZ|@LOLTrish hey  lo...|LOLTrish hey  lon...|\n",
      "|1467811795|Mon Apr 06 22:20:...|2Hood4Hollywood|@Tatiana_K nope t...|Tatiana_K nope th...|\n",
      "|1467812025|Mon Apr 06 22:20:...|        mimismo|@twittera que me ...|twittera que me m...|\n",
      "|1467812416|Mon Apr 06 22:20:...| erinx3leannexo|spring break in p...|spring break in p...|\n",
      "|1467812579|Mon Apr 06 22:20:...|   pardonlauren|I just re-pierced...|I just repierced ...|\n",
      "|1467812723|Mon Apr 06 22:20:...|           TLeC|@caregiving I cou...|caregiving I coul...|\n",
      "|1467812771|Mon Apr 06 22:20:...|robrobbierobert|@octolinz16 It it...|octolinz16 It it ...|\n",
      "|1467812784|Mon Apr 06 22:20:...|    bayofwolves|@smarrison i woul...|smarrison i would...|\n",
      "|1467812799|Mon Apr 06 22:20:...|     HairByJess|@iamjazzyfizzle I...|iamjazzyfizzle I ...|\n",
      "|1467812964|Mon Apr 06 22:20:...| lovesongwriter|Hollis' death sce...|Hollis death scen...|\n",
      "|1467813137|Mon Apr 06 22:20:...|       armotley|about to file taxes |about to file taxes |\n",
      "|1467813579|Mon Apr 06 22:20:...|     starkissed|@LettyA ahh ive a...|LettyA ahh ive al...|\n",
      "+----------+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- tweet_ID: integer (nullable = true)\n",
      " |-- date_timestamp: string (nullable = true)\n",
      " |-- twitter_user: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- cleaned_tweet_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema of the tweets dataset\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"tweet_ID\", IntegerType(), True),\n",
    "    StructField(\"date_timestamp\", StringType(), True),\n",
    "    StructField(\"twitter_user\", StringType(), True),\n",
    "    StructField(\"tweet_text\", StringType(), True),\n",
    "    StructField(\"cleaned_tweet_text\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load the dataset previosly saved with the colomuns\n",
    "# Tweet ID, Date / Timestamp,  Twitter User, Tweet text\n",
    "\n",
    "tweets_dataset = spark.read.csv('clean_table_tweets.csv', schema=schema, header=False)\n",
    "\n",
    "# tweets_dataset = spark.read.csv('clean_table_tweets_dataset.csv', schema=schema, header=False)\n",
    "\n",
    "# Show the first top 20 rows\n",
    "\n",
    "tweets_dataset.show()\n",
    "\n",
    "# Print the schema to verify\n",
    "\n",
    "tweets_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c7bffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/07 19:14:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 1:===========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|            tweet_ID|      date_timestamp|        twitter_user|          tweet_text|  cleaned_tweet_text|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|             1165608|             1598316|             1598316|             1598316|             1598243|\n",
      "|   mean|1.9151690781009285E9|                NULL| 4.325887521835714E9|                NULL|                NULL|\n",
      "| stddev| 1.575916195208061E8|                NULL|5.162733218454888E10|                NULL|                NULL|\n",
      "|    min|          1467810369|Fri Apr 17 20:30:...|        000catnap000|                 ...|\\t We love album ...|\n",
      "|    max|          2072532109|      date_timestamp|          zzzzeus111|ï¿½ï¿½ï¿½ï¿½ï¿½ß§...|ï½ï½ï½ï½ï½ßï½Çï½ï...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# The describe() function is a method that provides descriptive statistics which summarize the central tendency,\n",
    "# dispersion, and shape of a dataset’s distribution, excluding NaN values.\n",
    "# In this case, describe() function helps me. to see statistics like count, mean, standard deviation,\n",
    "# minimum, and maximum values for each column in the original DataFrame (tweets_dataset).\n",
    "# If the columns are categorical, it will include the count, unique, top, and frequency of the top value.\n",
    "\n",
    "# I am also using The show() function to display the DataFrame in a tabular format.\n",
    "# This is particularly useful when working in a console or interactive environment (like a Jupyter notebook).\n",
    "# It makes the data easier to understand and inspect visually.\n",
    "\n",
    "tweets_dataset.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6b3bc",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f117c",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaca3aa",
   "metadata": {},
   "source": [
    "Tweets are a great way to get qualitative data because they show feelings, thoughts, and responses.\n",
    "\n",
    "Sentiment analysis turns these feelings into numbers that can be used for statistical analysis.\n",
    "\n",
    "This helps to find bigger trends and patterns that might not notice just by reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f979a",
   "metadata": {},
   "source": [
    "### TextBlob Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00177525",
   "metadata": {},
   "source": [
    "**I am using TextBlob library, which provides a simple API for common natural language processing (NLP) tasks, including sentiment analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4717a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A User Defined Function (UDF) allows me to integrate custom Python logic into Spark DataFrame operations.\n",
    "# Here, I am creatting a UDF that uses TextBlob to perform sentiment analysis.\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Register the User Defined Function (UDF)\n",
    "\n",
    "sentiment_udf = udf(sentiment_analysis, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31010c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis UDF\n",
    "\n",
    "tweets_dataset = tweets_dataset.withColumn(\"senti_score_TextBlob\", sentiment_udf(tweets_dataset['cleaned_tweet_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91dbd1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|  cleaned_tweet_text|senti_score_TextBlob|\n",
      "+--------------------+--------------------+\n",
      "|  cleaned_tweet_text|                 0.0|\n",
      "|switchfoot httptw...|                 0.2|\n",
      "|is upset that he ...|                 0.0|\n",
      "|Kenichan I dived ...|                 0.5|\n",
      "|my whole body fee...|                 0.2|\n",
      "|nationwideclass n...|              -0.625|\n",
      "|Kwesidei not the ...|                 0.2|\n",
      "|         Need a hug |                 0.0|\n",
      "|LOLTrish hey  lon...|          0.27333334|\n",
      "|Tatiana_K nope th...|                 0.0|\n",
      "|twittera que me m...|                 0.0|\n",
      "|spring break in p...|         -0.21428572|\n",
      "|I just repierced ...|                 0.0|\n",
      "|caregiving I coul...|                 0.0|\n",
      "|octolinz16 It it ...|                 0.0|\n",
      "|smarrison i would...|               0.075|\n",
      "|iamjazzyfizzle I ...|                 0.0|\n",
      "|Hollis death scen...|                 0.0|\n",
      "|about to file taxes |                 0.0|\n",
      "|LettyA ahh ive al...|                 0.5|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Selecting and displaying only the required columns\n",
    "\n",
    "tweets_dataset.select(\"cleaned_tweet_text\", \"senti_score_TextBlob\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a50c7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TextBlob sentiment_analysis_tweets results back to a CSV file\n",
    "\n",
    "# tweets_dataset.write.csv('sentiment_analysis_textblob.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d488a7d",
   "metadata": {},
   "source": [
    "### Vader Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d0753",
   "metadata": {},
   "source": [
    "It uses a rule-based sentiment analysis framework, which excels in handling informal language typically found on Twitter, Facebook, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ac9d423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/geomarmunoz/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool\n",
    "# that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2b8d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment\n",
    "def vader_sentiment(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "# Register the UDF\n",
    "vader_sentiment_udf = udf(vader_sentiment, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52c89404",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dataset = tweets_dataset.withColumn(\"senti_score_Vader\", vader_sentiment_udf(tweets_dataset['cleaned_tweet_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58200de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|  cleaned_tweet_text|senti_score_Vader|\n",
      "+--------------------+-----------------+\n",
      "|  cleaned_tweet_text|              0.0|\n",
      "|switchfoot httptw...|          -0.3818|\n",
      "|is upset that he ...|          -0.7269|\n",
      "|Kenichan I dived ...|           0.4939|\n",
      "|my whole body fee...|            -0.25|\n",
      "|nationwideclass n...|          -0.6597|\n",
      "|Kwesidei not the ...|              0.0|\n",
      "|         Need a hug |           0.4767|\n",
      "|LOLTrish hey  lon...|           0.8286|\n",
      "|Tatiana_K nope th...|              0.0|\n",
      "|twittera que me m...|              0.0|\n",
      "|spring break in p...|              0.0|\n",
      "|I just repierced ...|              0.0|\n",
      "|caregiving I coul...|          -0.5994|\n",
      "|octolinz16 It it ...|          -0.1027|\n",
      "|smarrison i would...|           0.3724|\n",
      "|iamjazzyfizzle I ...|           0.2732|\n",
      "|Hollis death scen...|          -0.9081|\n",
      "|about to file taxes |              0.0|\n",
      "|LettyA ahh ive al...|           0.6369|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_dataset.select(\"cleaned_tweet_text\", \"senti_score_Vader\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62adc8a5",
   "metadata": {},
   "source": [
    "## TextBlob and Vader results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d934d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+\n",
      "|  cleaned_tweet_text|senti_score_Vader|senti_score_TextBlob|\n",
      "+--------------------+-----------------+--------------------+\n",
      "|  cleaned_tweet_text|              0.0|                 0.0|\n",
      "|switchfoot httptw...|          -0.3818|                 0.2|\n",
      "|is upset that he ...|          -0.7269|                 0.0|\n",
      "|Kenichan I dived ...|           0.4939|                 0.5|\n",
      "|my whole body fee...|            -0.25|                 0.2|\n",
      "|nationwideclass n...|          -0.6597|              -0.625|\n",
      "|Kwesidei not the ...|              0.0|                 0.2|\n",
      "|         Need a hug |           0.4767|                 0.0|\n",
      "|LOLTrish hey  lon...|           0.8286|          0.27333334|\n",
      "|Tatiana_K nope th...|              0.0|                 0.0|\n",
      "|twittera que me m...|              0.0|                 0.0|\n",
      "|spring break in p...|              0.0|         -0.21428572|\n",
      "|I just repierced ...|              0.0|                 0.0|\n",
      "|caregiving I coul...|          -0.5994|                 0.0|\n",
      "|octolinz16 It it ...|          -0.1027|                 0.0|\n",
      "|smarrison i would...|           0.3724|               0.075|\n",
      "|iamjazzyfizzle I ...|           0.2732|                 0.0|\n",
      "|Hollis death scen...|          -0.9081|                 0.0|\n",
      "|about to file taxes |              0.0|                 0.0|\n",
      "|LettyA ahh ive al...|           0.6369|                 0.5|\n",
      "+--------------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the results to verify\n",
    "\n",
    "tweets_dataset.select(\"cleaned_tweet_text\", \"senti_score_Vader\", \"senti_score_TextBlob\").show()\n",
    "\n",
    "# tweets_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fde4f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Vader sentiment_analysis_tweets results back to a CSV file\n",
    "\n",
    "# tweets_dataset.write.csv('sentiment_analysis_vader.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041493da",
   "metadata": {},
   "source": [
    "# Define UDFs for Sentiment Analysis\n",
    "Create UDFs for TextBlob and VADER, and also for sentiment classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b1616d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for TextBlob sentiment analysis\n",
    "\n",
    "def textblob_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "textblob_udf = udf(textblob_sentiment, FloatType())\n",
    "\n",
    "# UDF for VADER sentiment analysis\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "vader_udf = udf(vader_sentiment, FloatType())\n",
    "\n",
    "# UDF for sentiment classification based on the score\n",
    "\n",
    "def classify_sentiment(score):\n",
    "    if score > 0:\n",
    "        return 'Positive'\n",
    "    elif score < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "classify_udf = udf(classify_sentiment, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c66b7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis\n",
    "\n",
    "tweets_dataset = tweets_dataset.withColumn(\"TextBlob_Score\", textblob_udf(col(\"cleaned_tweet_text\")))\n",
    "tweets_dataset = tweets_dataset.withColumn(\"Vader_Score\", vader_udf(col(\"cleaned_tweet_text\")))\n",
    "\n",
    "# Classify sentiments\n",
    "\n",
    "tweets_dataset = tweets_dataset.withColumn(\"TextBlob_Sentiment\", classify_udf(col(\"TextBlob_Score\")))\n",
    "tweets_dataset = tweets_dataset.withColumn(\"Vader_Sentiment\", classify_udf(col(\"Vader_Score\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4db0cf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------------+\n",
      "|  cleaned_tweet_text|TextBlob_Sentiment|Vader_Sentiment|\n",
      "+--------------------+------------------+---------------+\n",
      "|  cleaned_tweet_text|           Neutral|        Neutral|\n",
      "|switchfoot httptw...|          Positive|       Negative|\n",
      "|is upset that he ...|           Neutral|       Negative|\n",
      "|Kenichan I dived ...|          Positive|       Positive|\n",
      "|my whole body fee...|          Positive|       Negative|\n",
      "|nationwideclass n...|          Negative|       Negative|\n",
      "|Kwesidei not the ...|          Positive|        Neutral|\n",
      "|         Need a hug |           Neutral|       Positive|\n",
      "|LOLTrish hey  lon...|          Positive|       Positive|\n",
      "|Tatiana_K nope th...|           Neutral|        Neutral|\n",
      "|twittera que me m...|           Neutral|        Neutral|\n",
      "|spring break in p...|          Negative|        Neutral|\n",
      "|I just repierced ...|           Neutral|        Neutral|\n",
      "|caregiving I coul...|           Neutral|       Negative|\n",
      "|octolinz16 It it ...|           Neutral|       Negative|\n",
      "|smarrison i would...|          Positive|       Positive|\n",
      "|iamjazzyfizzle I ...|           Neutral|       Positive|\n",
      "|Hollis death scen...|           Neutral|       Negative|\n",
      "|about to file taxes |           Neutral|        Neutral|\n",
      "|LettyA ahh ive al...|          Positive|       Positive|\n",
      "+--------------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Sentiment comparison table between TextBlob_Sentiment vs Vader_Sentimen\n",
    "\n",
    "tweets_dataset.select(['cleaned_tweet_text', 'TextBlob_Sentiment', 'Vader_Sentiment']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6c3f6",
   "metadata": {},
   "source": [
    "We can see that **Vader Sentiment is more accurate** because is tuned for sentiments expressed in social media and is optimized to understand text that includes emojis, slang, and shorthand, which makes it highly effective for datasets primarily composed of social media commentary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee205d",
   "metadata": {},
   "source": [
    "# This will continue in Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c147c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
